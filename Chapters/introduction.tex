\chapter{Introduction} 
\label{introduction} 

%Scientists create models as purposeful simplifications of phenomena that are too complex to be observed experimentally or to be solved analytically. Ancient greeks like Plato already built geometric models to describe the motion of heavenly bodies. Nowadays, scientists use models to study phenomena on a wide range of different scales ranging from quantum-mechanical effects to cosmic expansion. 

Understanding molecular processes is fundamental to a wide range of modern research areas, such as polymer science, drug design and folding dynamics of proteins. Novel algorithms and high-performance computing have made computational chemistry an important tool to gain insights on the molecular nature of matter. In particular, the importance of molecular models has to be emphasized, which are purposeful simplifications of phenomena that are too complex to be observed experimentally or to be solved analytically. As such, molecular modeling is routinely used to study the structure, thermodynamics and dynamics of molecular systems. 

On the other hand, processing of complex and high-dimensional data has become a hallmark of machine learning. In the past decade, ML has emergeded as a prominent research field that has an transformative impact on many domains, such as computer vision, speech recognition or medical image analysis.\cite{voulodimos2018deep, nassif2019speech, fatima2017survey} In its core, ML algorithms construct statistical models from data without relying on explicit program instructions. As such, the recent success of ML models is further fuelled by the availability of large data sets. Recently, ML is gaining significant attention in many fields of modern science as well, especially computational chemistry and particle physics \cite{noe2020machine, vamathevan2019applications, radovic2018machine}. 

The main theme of this thesis is to explore the advantages of integrating ML methods to molecular simulations. ML is already used frequently in the computational chemistry community to construct molecular models from experimental data or for the analysis of simulation data. Here, the emphasis is on generative tasks, i.e. deploying ML models to learn the complex depencies in molecular systems to generate realistic molecular structures. In particular, generative ML algorithms originally designed for image processing are applied to increase the resolution of coarse-grained molecular models. However, before the concept, methology and goal of this thesis are outlined in more detail, the broad context of this work has to be established first.

The theoretical underpinning of molecular models is given by statistical mechanics, which successfully explains macroscopic physical properties of matter in terms of microscopic degrees of freedom. However, while the fundamental principles to describe the motions of microscopic particles are well known, i.e. quantum-mechanics or Newton's equations of motion, the wast number of microscopic degrees of freedom that are required to predict properties of a particular macroscopic systems makes an analytical solution intractable. Moreover, resolving the microscopic state of a molecular system experimentally also displays resolution limits given by the applied microscopy technique. While a spatial resolution of a few angstrom can be achieved with modern microscopy techniques, such as cryo-EM or x-ray crystallography, a thourough understanding of molecular processes, such as protein folding, also required a high temporal resolution. However, microscopy techniques with high temporal resolution typically yield a lower spatial resolution, such as PALM or LLSM. While longer exposure times or short wavelengths could be used in the diffraction experiments to inscreaase the spatiotemporal resolution, the induced radiation damage prevents application of such techniques to biological systems. 

A possible remedy is offered by computer models that represent molecular systems based on experimental observations and analytical approximations. Simulations of the model can then be used to study the behavior of the system and to predict its properties. The resolution limit of such computer models is theoretically only bound by computational effort. The most fundamental description of matter is given by qunatum-mechanics that takes eletronic degrees of freedom into account. However, models at this level of detail are computationally very demanding. As an example, a popular method is density functional theory deploying B3LYP functionals, which scales as $\mathcal{O}(N^3)$, where $N$ is the number of atoms in the model system. The computational cost can be reduced significatnly when molecular models at an atomistic resolution are deployed that approximate the effect of electrons as a potential energy surface representing the quantum ground-state. Such models are typically implemented by molecular dynamics simulations that numerically integrate Newton's equations of motion. The underlying interactions are often empirical and aim at correctly modeling structural, thermodynamic and/or dynamic properties of a target system. The computational effort of such classical models is dominated by long-range interactions, such as van-der-waals and electrostatic interactions, which are typically inetgrated using particle mesh Ewald summation that reduce the computational cost to $N \text{log}(N)$.

Rapid fluctuations of the atoms typically require an integration time step in the range of femtoseconds. However, timescales of relevant biological processes, such as protein folding or binding, can be in the order of microseconds up to seconds and therefore require an extremely large number of integration steps. As such, even dedicated hardware and specialized software reach their limits, as current state-of-the-art integration systems achieve hundrets of nanoseconds up to tens of microseconds of simulation data per day for molecular systems containing a few thousands of atoms. Therefore, a coarser description of matter is often required in order to push the limits of accessible length and time scales in the computer simulation.

The resolution of a molecular model depends on the length and time scales of the phenomena of interest. However, some phenomena display a wide range of relevant scales and therefore can not be captured by a single model. This is especially true for soft-matter systems, like polymers or complex liquids, where processes on multiple scales are linked and interwoven \cite{praprotnik2008multiscale, peter2010multiscale, peter2009multiscale}. In particular, local interactions can impact large scale conformational changes. Consequently, molecular modeling of soft matter systems requires a methology that captures the interplay of processes that are potentially linked to various different scales.

A solution is offered by multiscale modelling, where models of different resolutions are combined to address phenomena at multiple scales. At the lower end, coarse-grained molecular models are deployed to study the large scale behavior of the system. To this end, coarse-grained variables are used that represent an average over atomistic degrees of freedom. The lower resolution of coarse-grained systems reduces the computational effort of the simulation. In addition, dynamics of the coarse-grained system are typically accelerated due to "softer" interactions between coarse-grained sites. As such, a faster exploration of configuration space is possible. 

A tight and consistent link between models of different resolutions requires to accomplished both mapping directions. While the benefits of coarse-graining is evident, a reverse-mapping to reintroduce details is required for the following reasons: (1) To rigorously analyze the simulation results on a local scale \cite{brocos2012multiscale, pandey2014multiscale, deshmukh2016water, pezeshkian2020backmapping}, (2) to enable a direct comparison to experimental data, for example obtained with spectroscopic methods \cite{hess2006long}, (3) to serve as starting point for further high-resolution simulations \cite{shimizu2018reconstruction, pandey2014multiscale}, or (4) to asses the stability and accuracy of the obtained coarse-grained structures \cite{shimizu2018reconstruction}.


The fine-to-coarse mapping of molecular configurations is typically a straight-forward computation, such as the center-of-mass calculation for a set of atoms. However, a reverse-mapping scheme is more challenging. 

that reintroduces details is more challenging for the following reasons: required as well, for example to allow for a stringend comparison to experimental observations.

going the other direction is required as well, since a stringend comparison to experimental results often requires atomistic details. Therefore, multisclae modelling 


